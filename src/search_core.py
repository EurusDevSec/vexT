import json  # <--- ÄÃƒ THÃŠM VÃ€O ÄÃ‚Y
import os
from opensearchpy import OpenSearch, helpers
from sentence_transformers import SentenceTransformer

# --- Cáº¤U HÃŒNH ---
# Cáº­p nháº­t cáº¥u hÃ¬nh káº¿t ná»‘i cho OpenSearch Docker (Báº£o máº­t máº·c Ä‘á»‹nh)
auth = ('admin', 'StrongPassword123!')  # Máº­t kháº©u Ä‘Ã£ set trong docker-compose.yml

client = OpenSearch(
    hosts=[{'host': 'localhost', 'port': 9200}],
    http_compress=True,
    http_auth=auth,         # ThÃªm xÃ¡c thá»±c Basic Auth
    use_ssl=True,           # Báº­t SSL vÃ¬ OpenSearch máº·c Ä‘á»‹nh dÃ¹ng HTTPS
    verify_certs=False,     # Bá» qua check chá»©ng chá»‰ (vÃ¬ dÃ¹ng self-signed trong Docker)
    ssl_assert_hostname=False,
    ssl_show_warn=False
)

INDEX_NAME = "vext_products"

# Load model AI
print("â³ Äang táº£i model AI cho tÃ¬m kiáº¿m...")
model = SentenceTransformer('all-MiniLM-L6-v2')

def create_index():
    print(f"ğŸ› ï¸ Äang thiáº¿t láº­p INDEX_MAPPING cho {INDEX_NAME}...")

    # Define data structure (schema)
    index_body = {
        "settings": {
            "index": {
                "knn": True,                        # KÃ­ch hoáº¡t plugin Vector
                "knn.algo_param.ef_search": 100,    # Tinh chá»‰nh tá»‘c Ä‘á»™ tÃ¬m kiáº¿m
                "number_of_shards": 1,              # Demo dÃ¹ng 1 shard cho nháº¹
                "number_of_replicas": 0             # Táº¯t replica tiáº¿t kiá»‡m á»• cá»©ng
            }
        },
        "mappings": {
            "dynamic": "strict", # Quan trá»ng: Cháº·n OpenSearch tá»± Ä‘oÃ¡n kiá»ƒu dá»¯ liá»‡u
            "properties": {
                # --- Metadata ChÃ­nh xÃ¡c (Keyword) ---
                "id": { "type": "keyword" },        # Lookup nhanh
                "category": { "type": "keyword" },  # Lá»c chÃ­nh xÃ¡c
                "brand": { "type": "keyword" },
                
                # --- Metadata Pháº¡m vi (Range) ---
                "price": { "type": "float" },       # Lá»c giÃ¡
                "publish_date": { 
                    "type": "date",
                    "format": "strict_date_optional_time||epoch_millis"
                },

                # --- TÃ¬m kiáº¿m ToÃ n vÄƒn (Full-Text) ---
                "title": { 
                    "type": "text", 
                    "analyzer": "standard",
                    "fields": {
                        "keyword": { "type": "keyword" } 
                    }
                },
                "content_text": { "type": "text" }, 
                
                # --- Vector Search (k-NN HNSW) ---
                "embedding": {
                    "type": "knn_vector",
                    "dimension": 384,               # Khá»›p model MiniLM
                    "method": {
                        "name": "hnsw",             # Thuáº­t toÃ¡n SOTA
                        "space_type": "cosinesimil",
                        "engine": "nmslib",
                        "parameters": {
                            "ef_construction": 128,
                            "m": 16
                        }
                    }
                }
            }
        }
    }
    
    # XÃ³a index cÅ©
    if client.indices.exists(index=INDEX_NAME):
        client.indices.delete(index=INDEX_NAME)
        print(f"   ğŸ—‘ï¸ ÄÃ£ xÃ³a index cÅ© '{INDEX_NAME}'.")
        
    # Táº¡o index má»›i
    try:
        client.indices.create(index=INDEX_NAME, body=index_body)
        print(f"   âœ… ÄÃ£ táº¡o Index '{INDEX_NAME}' thÃ nh cÃ´ng vá»›i HNSW (m=16, ef=128).")
    except Exception as e:
        print(f"   âŒ Lá»—i táº¡o index: {e}")

def ingest_data():
    # ÄÆ°á»ng dáº«n file json
    dir_script = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    file_path = os.path.join(dir_script, "res", "product_ready.json")
    
    print(f"ğŸ”„ Äang Ä‘á»c dá»¯ liá»‡u tá»« {file_path}...")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            products = json.load(f)
        
        # Chuáº©n bá»‹ dá»¯ liá»‡u bulk
        actions = []
        for product in products:
            action = {
                "_index": INDEX_NAME,
                "_source": product
            }
            actions.append(action)
        
        # Gá»­i lÃªn Server
        helpers.bulk(client, actions)
        print(f"ğŸš€ ÄÃ£ náº¡p thÃ nh cÃ´ng {len(actions)} sáº£n pháº©m vÃ o OpenSearch.")
        
        # Refresh Ä‘á»ƒ tÃ¬m tháº¥y ngay
        client.indices.refresh(index=INDEX_NAME)
    except FileNotFoundError:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {file_path}. HÃ£y cháº¡y etl_pipeline.py trÆ°á»›c!")

def search_hybrid(user_query, min_price=0):
    print(f"\nğŸ” Äang tÃ¬m kiáº¿m: '{user_query}' (GiÃ¡ > {min_price})...")
    
    # B1: Vector hÃ³a
    query_vector = model.encode(user_query).tolist()
    
    # B2: Query DSL
    query_body = {
        "size": 3,
        "query": {
            "bool": {
                "filter": {
                    "range": {
                        "price": {"gte": min_price}
                    }
                },
                "should": [
                    {
                        "multi_match": {
                            "query": user_query,
                            "fields": ["title^2", "content_text"],
                            "boost": 0.3
                        }
                    },
                    {
                        "knn": {
                            "embedding": {
                                "vector": query_vector,
                                "k": 3,
                                "boost": 0.7
                            }
                        }
                    }
                ]
            }
        }
    }
    
    # B3: Thá»±c thi
    try:
        response = client.search(index=INDEX_NAME, body=query_body)
        print(f"--- Káº¾T QUáº¢ TÃŒM KIáº¾M CHO: '{user_query}' ---")
        if not response['hits']['hits']:
            print("   (KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ nÃ o)")
        
        for hit in response['hits']['hits']:
            score = hit['_score']
            source = hit['_source']
            print(f"â­ Score: {score:.4f} | ğŸ·ï¸ {source['title']} | ğŸ’° {source['price']:,.0f} VNÄ")
            print(f"   â„¹ï¸ {source['content_text'][:100]}...") 
            print("-" * 30)
    except Exception as e:
        print(f"âŒ Lá»—i tÃ¬m kiáº¿m: {e}")

# --- PHáº¦N CHáº Y CHÃNH (MAIN BLOCK) ---
if __name__ == "__main__":
    try:
        # 1. Táº¡o cáº¥u trÃºc báº£ng (Mapping)
        create_index()
        
        # 2. Náº¡p dá»¯ liá»‡u vÃ o báº£ng
        ingest_data()
        
        # 3. Cháº¡y thá»­ tÃ¬m kiáº¿m
        # Ká»‹ch báº£n 1: TÃ¬m mÃ¡y tÃ­nh code (Ngá»¯ nghÄ©a) + Lá»c giÃ¡ > 10 triá»‡u
        search_hybrid("MÃ¡y tÃ­nh cho dÃ¢n code", min_price=10000000)
        
        # Ká»‹ch báº£n 2: TÃ¬m chuá»™t (Tá»« khÃ³a chÃ­nh xÃ¡c) + KhÃ´ng lá»c giÃ¡
        search_hybrid("Chuá»™t Logitech", min_price=0)
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ÄÃ£ dá»«ng chÆ°Æ¡ng trÃ¬nh.")
    except Exception as e:
        print(f"\nâŒ CÃ³ lá»—i xáº£y ra: {e}")