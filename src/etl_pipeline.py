import pandas as pd
import numpy as np 
# ChÃº Ã½: ThÆ° viá»‡n tÃªn lÃ  sentence_transformers (cÃ³ chá»¯ s á»Ÿ cuá»‘i)
from sentence_transformers import SentenceTransformer 
import os

# --- Cáº¤U HÃŒNH ---
print("Loading model AI... ")
model = SentenceTransformer('all-MiniLM-L6-v2')

# XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n file
dir_script = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# Táº¡o thÆ° má»¥c res náº¿u chÆ°a cÃ³
os.makedirs(os.path.join(dir_script, "res"), exist_ok=True)
file_path = os.path.join(dir_script, "res", "products.csv")

# --- HÃ€M Táº O Dá»® LIá»†U MáºªU (Fix lá»—i CSV cá»§a báº¡n) ---
def create_dummy_data():
    print("ğŸ› ï¸ Äang táº¡o file dá»¯ liá»‡u máº«u chuáº©n (products.csv)...")
    data = [
        {
            "id": 1,
            "title": "Laptop Dell XPS 13",
            "category": "Electronics",
            "publish_date": "2023-10-01",
            "price": 25000000,
            "content_text": "MÃ¡y tÃ­nh xÃ¡ch tay Dell XPS 13 mÃ n hÃ¬nh vÃ´ cá»±c, chip Intel Core i7, RAM 16GB, SSD 512GB. Thiáº¿t káº¿ má»ng nháº¹ doanh nhÃ¢n."
        },
        {
            "id": 2,
            "title": "iPhone 15 Pro Max",
            "category": "Mobile",
            "publish_date": "2023-09-15",
            "price": 30000000,
            "content_text": "Äiá»‡n thoáº¡i iPhone 15 Pro Max vá» titan, chip A17 Pro, camera 48MP zoom quang há»c 5x. MÃ u xanh titan tá»± nhiÃªn."
        },
        {
            "id": 3,
            "title": "Chuá»™t Logitech MX Master 3",
            "category": "Accessories",
            "publish_date": "2023-01-20",
            "price": 2500000,
            "content_text": "Chuá»™t khÃ´ng dÃ¢y Logitech MX Master 3S, thiáº¿t káº¿ cÃ´ng thÃ¡i há»c, cuá»™n siÃªu nhanh MagSpeed, pin sáº¡c USB-C."
        },
        {
            "id": 4,
            "title": "SÃ¡ch Clean Code",
            "category": "Books",
            "publish_date": None, # Test dá»¯ liá»‡u thiáº¿u ngÃ y
            "price": 500000,
            "content_text": "Cuá»‘n sÃ¡ch Clean Code cá»§a Robert C. Martin hÆ°á»›ng dáº«n cÃ¡ch viáº¿t mÃ£ sáº¡ch, dá»… báº£o trÃ¬ vÃ  tá»‘i Æ°u cho láº­p trÃ¬nh viÃªn."
        },
        {
            "id": 5,
            "title": None, # Test thiáº¿u tiÃªu Ä‘á»
            "category": "Unknown",
            "publish_date": "2022-12-12",
            "price": 0,
            "content_text": "Dá»¯ liá»‡u bá»‹ lá»—i tiÃªu Ä‘á» nhÆ°ng váº«n cÃ³ ná»™i dung mÃ´ táº£ Ä‘á»ƒ test vector."
        }
    ]
    # Táº¡o DataFrame vÃ  lÆ°u ra CSV chuáº©n
    df = pd.DataFrame(data)
    df.to_csv(file_path, index=False, encoding='utf-8')
    print("âœ… ÄÃ£ táº¡o file products.csv thÃ nh cÃ´ng!")

# --- CÃC HÃ€M Xá»¬ LÃ (ETL) ---
def normalize_data(file_path):
    print(f"ğŸ”„ Äang Ä‘á»c dá»¯ liá»‡u tá»«: {file_path}")
    df = pd.read_csv(file_path)
    
    # Xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u (Fill NA)
    df["category"] = df["category"].fillna("Unknown")
    df["title"] = df["title"].fillna("Unknown Product")

    # Chuáº©n hÃ³a chuá»—i (String Cleaning)
    df["category"] = df["category"].apply(lambda x: str(x).strip().title())
    
    # Chuáº©n hÃ³a ngÃ y thÃ¡ng (Date Parsing)
    # errors='coerce' nghÄ©a lÃ : náº¿u lá»—i thÃ¬ biáº¿n thÃ nh NaT (trá»‘ng) chá»© khÃ´ng bÃ¡o lá»—i dá»«ng chÆ°Æ¡ng trÃ¬nh
    df["publish_date"] = pd.to_datetime(df["publish_date"], errors="coerce")

    # Lá»c rÃ¡c (Filter Garbage)
    # Chá»‰ xÃ³a nhá»¯ng dÃ²ng KHÃ”NG CÃ“ ná»™i dung mÃ´ táº£ (vÃ¬ khÃ´ng táº¡o vector Ä‘Æ°á»£c)
    init_count = len(df)
    df = df.dropna(subset=["content_text"])
    
    if init_count - len(df) > 0:
        print(f"âš ï¸ ÄÃ£ lá»c bá» {init_count - len(df)} dÃ²ng thiáº¿u ná»™i dung mÃ´ táº£.")

    return df 

def generate_vectors(df):
    print("ğŸ§  Äang táº¡o Vector Embeddings (Vectorization)...")
    
    # Láº¥y danh sÃ¡ch text
    sentences = df['content_text'].tolist()
    
    # Táº¡o vector (Batch process)
    embeddings = model.encode(sentences, show_progress_bar=True)
    
    # Chuyá»ƒn vá» dáº¡ng List Ä‘á»ƒ OpenSearch hiá»ƒu
    df['embedding'] = list(embeddings)
    
    print(f"âœ… ÄÃ£ táº¡o vector thÃ nh cÃ´ng cho {len(df)} dÃ²ng dá»¯ liá»‡u.")
    return df

def main():
    try:
        # BÆ¯á»šC 0: Tá»° Äá»˜NG Táº O DATA CHUáº¨N
        create_dummy_data()

        # BÆ¯á»šC 1: ETL
        df_clean = normalize_data(file_path)

        # BÆ¯á»šC 2: VECTOR HÃ“A
        df_final = generate_vectors(df_clean)
        
        # BÆ¯á»šC 3: Káº¾T QUáº¢
        print("\n--- Káº¾T QUáº¢ KIá»‚M TRA (SAMPLE) ---")
        # In ra 3 cá»™t quan trá»ng Ä‘á»ƒ check xem cÃ²n bá»‹ lá»‡ch khÃ´ng
        print(df_final[['title', 'category', 'price', 'publish_date']].head())
        
        # Kiá»ƒm tra kÃ­ch thÆ°á»›c vector dÃ²ng Ä‘áº§u tiÃªn
        vector_dim = len(df_final['embedding'].iloc[0])
        print(f"\nğŸ“ KÃ­ch thÆ°á»›c Vector: {vector_dim} chiá»u (Chuáº©n SOTA)")

        # LÆ°u káº¿t quáº£ ra JSON Ä‘á»ƒ dÃ¹ng cho bÆ°á»›c sau
        output_path = os.path.join(dir_script, "res", "product_ready.json")
        df_final.to_json(output_path, orient='records', date_format='iso')
        print(f"ğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ vÃ o: {output_path}")

    except KeyboardInterrupt:
        print("System stopped by user")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")

if __name__ == "__main__":
    main()