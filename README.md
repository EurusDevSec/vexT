# vexT - Hybrid Search & RAG System

![Project Banner](image.png)

**vexT** lÃ  má»™t há»‡ thá»‘ng tÃ¬m kiáº¿m thÃ´ng minh káº¿t há»£p giá»¯a **Hybrid Search** (Keyword + Vector) vÃ  **RAG** (Retrieval-Augmented Generation) Ä‘á»ƒ cung cáº¥p cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c dá»±a trÃªn dá»¯ liá»‡u sáº£n pháº©m thá»±c táº¿.

Dá»± Ã¡n sá»­ dá»¥ng **OpenSearch** lÃ m cÃ´ng cá»¥ tÃ¬m kiáº¿m vector, **SentenceTransformers** Ä‘á»ƒ táº¡o embedding, vÃ  **Google Gemini** Ä‘á»ƒ tá»•ng há»£p cÃ¢u tráº£ lá»i.

---

## ğŸš€ TÃ­nh nÄƒng chÃ­nh

- **Hybrid Search**: Káº¿t há»£p sá»©c máº¡nh cá»§a tÃ¬m kiáº¿m tá»« khÃ³a (BM25) vÃ  tÃ¬m kiáº¿m ngá»¯ nghÄ©a (k-NN/Vector) sá»­ dá»¥ng thuáº­t toÃ¡n HNSW + FAISS.
- **RAG Engine**: TÃ­ch há»£p Google Gemini 2.0 Flash Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i tá»± nhiÃªn dá»±a trÃªn káº¿t quáº£ tÃ¬m kiáº¿m.
- **ETL Pipeline**: Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u tá»± Ä‘á»™ng tá»« CSV sang Vector Index.
- **Giao diá»‡n Streamlit**: UI thÃ¢n thiá»‡n Ä‘á»ƒ tÃ¬m kiáº¿m vÃ  chat vá»›i dá»¯ liá»‡u.

## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng

- **Core**: Python 3.12+
- **Search Engine**: OpenSearch (Docker)
- **LLM**: Google Gemini (via Google GenAI SDK)
- **Embedding**: `all-MiniLM-L6-v2`
- **Frontend**: Streamlit
- **Quáº£n lÃ½ gÃ³i**: `uv` (hoáº·c pip)

---

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

1. **Docker Desktop** (Ä‘á»ƒ cháº¡y OpenSearch).
2. **Python 3.12** trá»Ÿ lÃªn.
3. **Google API Key** (Ä‘á»ƒ sá»­ dá»¥ng Gemini).

---

## âš™ï¸ CÃ i Ä‘áº·t

### 1. Clone dá»± Ã¡n

```bash
git clone https://github.com/EurusDevSec/vexT.git
cd vexT
```

### 2. Cáº¥u hÃ¬nh biáº¿n mÃ´i trÆ°á»ng

Táº¡o file `.env` táº¡i thÆ° má»¥c gá»‘c vÃ  thÃªm API Key cá»§a báº¡n:

```env
GOOGLE_API_KEY=your_google_api_key_here
```

### 3. CÃ i Ä‘áº·t thÆ° viá»‡n

Dá»± Ã¡n sá»­ dá»¥ng `uv` Ä‘á»ƒ quáº£n lÃ½ gÃ³i. Náº¿u chÆ°a cÃ³ `uv`, báº¡n cÃ³ thá»ƒ cÃ i Ä‘áº·t hoáº·c dÃ¹ng `pip`.

**CÃ¡ch 1: DÃ¹ng uv (KhuyÃªn dÃ¹ng)**

```bash
# Táº¡i thÆ° má»¥c gá»‘c
cd src
uv sync
```

**CÃ¡ch 2: DÃ¹ng pip**

```bash
pip install -r requirements.txt
# Hoáº·c cÃ i thá»§ cÃ´ng cÃ¡c thÆ° viá»‡n trong pyproject.toml
pip install opensearch-py sentence-transformers pandas streamlit google-generativeai python-dotenv
```

---

## â–¶ï¸ HÆ°á»›ng dáº«n cháº¡y

### BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng OpenSearch

# vexT â€” Hybrid Search and RAG

![Project Banner](image.png)

vexT is a prototype hybrid search and retrieval-augmented generation (RAG) system that combines keyword search (BM25) with semantic vector search to deliver context-aware answers over product data. The project demonstrates an end-to-end pipeline: ETL, embedding, vector indexing (OpenSearch + FAISS), hybrid retrieval, and answer generation via Google Gemini.

Key components:

- OpenSearch (vector-enabled) as the search backend
- SentenceTransformers (`all-MiniLM-L6-v2`) for embeddings
- Google Gemini (via Google GenAI SDK) for RAG response generation
- Streamlit for a simple web UI

---

## Features

- Hybrid retrieval: BM25 (text) + approximate k-NN (vector) using HNSW + FAISS
- RAG: contextual answer synthesis using retrieved documents
- ETL pipeline to normalize and convert product CSV into indexed documents
- Streamlit demo app for interactive search and question answering

---

## Requirements

- Docker Desktop (to run the OpenSearch cluster)
- Python 3.12+
- A Google Cloud API key with access to the GenAI endpoint (set via `GOOGLE_API_KEY`)

---

## Quickstart

Follow these steps to run the project locally.

1. Clone the repository

```bash
git clone https://github.com/EurusDevSec/vexT.git
cd vexT
```

2. Configure environment variables

Create a `.env` file in the repository root with your Google API key:

```env
GOOGLE_API_KEY=your_google_api_key_here
```

3. Install Python dependencies

The project uses `uv` for dependency management; you can use it if available, otherwise use `pip`.

Recommended (uv):

```bash
cd src
uv sync
```

Alternative (pip):

```bash
pip install -r requirements.txt
# or install packages manually from src/pyproject.toml
```

4. Start OpenSearch

From the `infra/` directory:

```bash
cd infra
docker-compose up -d
```

Allow 1â€“2 minutes for OpenSearch to fully initialize.

5. Run the ETL pipeline

Place your `flipkart_data.csv` file inside the `res/` folder, then run:

```bash
# from project root
cd src
uv run etl_pipeline.py   # or: python etl_pipeline.py
```

This will normalize the CSV, generate embeddings, and export a JSON file ready for indexing.

6. Index data into OpenSearch

```bash
cd src
uv run search_core.py    # or: python search_core.py
```

7. Launch the demo UI

```bash
cd src
uv run streamlit run app.py   # or: streamlit run app.py
```

Open the URL shown by Streamlit (usually http://localhost:8501).

---

## Project layout

```
vexT/
â”œâ”€â”€ docs/            # Technical documentation
â”œâ”€â”€ infra/           # Docker compose for OpenSearch
â”œâ”€â”€ res/             # Input datasets (e.g. flipkart_data.csv)
â”œâ”€â”€ src/             # Application source code
â”‚   â”œâ”€â”€ app.py       # Streamlit demo
â”‚   â”œâ”€â”€ etl_pipeline.py
â”‚   â”œâ”€â”€ search_core.py
â”‚   â”œâ”€â”€ rag_engine.py
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## Notes and tips

- Default OpenSearch credentials (configured in `infra/docker-compose.yml`): `admin` / `StrongPassword123!`.
- The ETL mapping (column names) is configurable in `src/etl_pipeline.py` to accommodate other datasets.
- For development, the heap settings in `infra/docker-compose.yml` are conservative; increase them for larger datasets or production use.

If you want, I can also: add a `requirements.txt`, create a small `Makefile` for the common commands, or add unit tests for the ETL and search modules.
